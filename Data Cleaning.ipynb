{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this excercise we combine several messy data sets into a single clean one to make analysis easier. Over the next few missions, we'll work through the rest of our project and perform the actual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read each file into a pandas dataframe, and then store all of the dataframes in a dictionary. This will give us a convenient way to store them, and a quick way to reference them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "data = {}\n",
    "\n",
    "for f in data_files:\n",
    "    d = pd.read_csv(\"{0}\".format(f))\n",
    "    key_name = f.replace(\".csv\", \"\")\n",
    "    data[key_name] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the SAT Data\n",
    "\n",
    "What we're mainly interested in is the SAT data set, which corresponds to the dictionary key sat_results. This data set contains the SAT scores for each high school in New York City. We eventually want to correlate selected information from this data set with information in the other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>SCHOOL NAME</th>\n",
       "      <th>Num of SAT Test Takers</th>\n",
       "      <th>SAT Critical Reading Avg. Score</th>\n",
       "      <th>SAT Math Avg. Score</th>\n",
       "      <th>SAT Writing Avg. Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>29</td>\n",
       "      <td>355</td>\n",
       "      <td>404</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>91</td>\n",
       "      <td>383</td>\n",
       "      <td>423</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>70</td>\n",
       "      <td>377</td>\n",
       "      <td>402</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M458</td>\n",
       "      <td>FORSYTH SATELLITE ACADEMY</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M509</td>\n",
       "      <td>MARTA VALLE HIGH SCHOOL</td>\n",
       "      <td>44</td>\n",
       "      <td>390</td>\n",
       "      <td>433</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DBN                                    SCHOOL NAME  \\\n",
       "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
       "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
       "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
       "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
       "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
       "\n",
       "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
       "0                     29                             355                 404   \n",
       "1                     91                             383                 423   \n",
       "2                     70                             377                 402   \n",
       "3                      7                             414                 401   \n",
       "4                     44                             390                 433   \n",
       "\n",
       "  SAT Writing Avg. Score  \n",
       "0                    363  \n",
       "1                    366  \n",
       "2                    370  \n",
       "3                    359  \n",
       "4                    384  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sat_results'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the Remaining Data\n",
    "\n",
    "When we printed the first five rows of the SAT data, the output looked like this:\n",
    "\n",
    "for f in data.keys():\n",
    "    print(\"{0} is \\n\".format(f),data[f].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can make some observations based on the first few rows of each one.\n",
    "\n",
    "    Each data set appears to either have a DBN column, or the information we need to create one. That means we can use a DBN column to combine the data sets. First we'll pinpoint matching rows from different data sets by looking for identical DBNs, then group all of their columns together in a single data set.\n",
    "    Some fields look interesting for mapping -- particularly Location 1, which contains coordinates inside a larger string.\n",
    "    Some of the data sets appear to contain multiple rows for each school (because the rows have duplicate DBN values). That means weâ€™ll have to do some preprocessing to ensure that each DBN is unique within each data set. If we don't do this, we'll run into problems when we combine the data sets, because we might be merging two rows in one data set with one row in another data set.\n",
    "\n",
    "Before we proceed with the merge, we should make sure we have all of the data we want to unify. We mentioned the survey data earlier (survey_all.txt and survey_d75.txt), but we didn't read those files in because they're in a slightly more complex format.\n",
    "\n",
    "Each survey text file looks like this:\n",
    "\n",
    "dbn bn  schoolname  d75 studentssurveyed    highschool  schooltype  rr_s\n",
    "\n",
    "\"01M015\"    \"M015\"  \"P.S. 015 Roberto Clemente\" 0   \"No\"    0   \"Elementary School\"     88\n",
    "\n",
    "The files are tab delimited and encoded with Windows-1252 encoding. An encoding defines how a computer stores the contents of a file in binary. The most common encodings are UTF-8 and ASCII. Windows-1252 is rarely used, and can cause errors if we read such a file in without specifying the encoding. If you'd like to read more about encodings, here's a good primer.\n",
    "\n",
    "We'll need to specify the encoding and delimiter to the pandas pandas.read_csv() function to ensure it reads the surveys in properly.\n",
    "\n",
    "After we read in the survey data, we'll want to combine it into a single dataframe. We can do this by calling the pandas.concat() function:\n",
    "\n",
    "z = pd.concat([x,y], axis=0)\n",
    "\n",
    "The code above will combine dataframes x and y by essentially appending y to the end of x. The combined dataframe z will have the number of rows in x plus the number of rows in y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_p</th>\n",
       "      <th>N_s</th>\n",
       "      <th>N_t</th>\n",
       "      <th>aca_p_11</th>\n",
       "      <th>aca_s_11</th>\n",
       "      <th>aca_t_11</th>\n",
       "      <th>aca_tot_11</th>\n",
       "      <th>bn</th>\n",
       "      <th>com_p_11</th>\n",
       "      <th>com_s_11</th>\n",
       "      <th>...</th>\n",
       "      <th>t_q8c_1</th>\n",
       "      <th>t_q8c_2</th>\n",
       "      <th>t_q8c_3</th>\n",
       "      <th>t_q8c_4</th>\n",
       "      <th>t_q9</th>\n",
       "      <th>t_q9_1</th>\n",
       "      <th>t_q9_2</th>\n",
       "      <th>t_q9_3</th>\n",
       "      <th>t_q9_4</th>\n",
       "      <th>t_q9_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>M015</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>M019</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>M020</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>M034</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>M063</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     N_p    N_s   N_t  aca_p_11  aca_s_11  aca_t_11  aca_tot_11    bn  \\\n",
       "0   90.0    NaN  22.0       7.8       NaN       7.9         7.9  M015   \n",
       "1  161.0    NaN  34.0       7.8       NaN       9.1         8.4  M019   \n",
       "2  367.0    NaN  42.0       8.6       NaN       7.5         8.0  M020   \n",
       "3  151.0  145.0  29.0       8.5       7.4       7.8         7.9  M034   \n",
       "4   90.0    NaN  23.0       7.9       NaN       8.1         8.0  M063   \n",
       "\n",
       "   com_p_11  com_s_11   ...    t_q8c_1  t_q8c_2  t_q8c_3 t_q8c_4  t_q9  \\\n",
       "0       7.6       NaN   ...       29.0     67.0      5.0     0.0   NaN   \n",
       "1       7.6       NaN   ...       74.0     21.0      6.0     0.0   NaN   \n",
       "2       8.3       NaN   ...       33.0     35.0     20.0    13.0   NaN   \n",
       "3       8.2       5.9   ...       21.0     45.0     28.0     7.0   NaN   \n",
       "4       7.9       NaN   ...       59.0     36.0      5.0     0.0   NaN   \n",
       "\n",
       "   t_q9_1  t_q9_2  t_q9_3  t_q9_4  t_q9_5  \n",
       "0     5.0    14.0    52.0    24.0     5.0  \n",
       "1     3.0     6.0     3.0    78.0     9.0  \n",
       "2     3.0     5.0    16.0    70.0     5.0  \n",
       "3     0.0    18.0    32.0    39.0    11.0  \n",
       "4    10.0     5.0    10.0    60.0    15.0  \n",
       "\n",
       "[5 rows x 2773 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_survey=pd.read_csv('survey_all.txt',encoding=\"windows-1252\",delimiter=\"\\t\")\n",
    "d75_survey=pd.read_csv('survey_d75.txt',encoding=\"windows-1252\",delimiter=\"\\t\")\n",
    "survey=pd.concat([all_survey,d75_survey],axis=0)\n",
    "survey.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN  rr_s  rr_t  rr_p    N_s   N_t    N_p  saf_p_11  com_p_11  eng_p_11  \\\n",
      "0  01M015   NaN    88    60    NaN  22.0   90.0       8.5       7.6       7.5   \n",
      "1  01M019   NaN   100    60    NaN  34.0  161.0       8.4       7.6       7.6   \n",
      "2  01M020   NaN    88    73    NaN  42.0  367.0       8.9       8.3       8.3   \n",
      "3  01M034  89.0    73    50  145.0  29.0  151.0       8.8       8.2       8.0   \n",
      "4  01M063   NaN   100    60    NaN  23.0   90.0       8.7       7.9       8.1   \n",
      "\n",
      "      ...      eng_t_11  aca_t_11  saf_s_11  com_s_11  eng_s_11  aca_s_11  \\\n",
      "0     ...           7.6       7.9       NaN       NaN       NaN       NaN   \n",
      "1     ...           8.9       9.1       NaN       NaN       NaN       NaN   \n",
      "2     ...           6.8       7.5       NaN       NaN       NaN       NaN   \n",
      "3     ...           6.8       7.8       6.2       5.9       6.5       7.4   \n",
      "4     ...           7.8       8.1       NaN       NaN       NaN       NaN   \n",
      "\n",
      "   saf_tot_11  com_tot_11  eng_tot_11  aca_tot_11  \n",
      "0         8.0         7.7         7.5         7.9  \n",
      "1         8.5         8.1         8.2         8.4  \n",
      "2         8.2         7.3         7.5         8.0  \n",
      "3         7.3         6.7         7.1         7.9  \n",
      "4         8.5         7.6         7.9         8.0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "#For consistency ,we rename the column dbn to DBN\n",
    "survey[\"DBN\"]=survey[\"dbn\"]\n",
    "cols_to_be_filtered=[\"DBN\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\", \"com_p_11\", \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\", \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n",
    "survey=survey.loc[:,cols_to_be_filtered]\n",
    "data[\"survey\"]=survey\n",
    "print(survey.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting DBN Fields\n",
    "\n",
    "When we explored all of the data sets, we noticed that some of them, like class_size and hs_directory, don't have a DBN column. hs_directory does have a dbn column, though, so we can just rename it.\n",
    "\n",
    "However, class_size doesn't appear to have the column at all. Here are the first few rows of the data set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CSD BOROUGH SCHOOL CODE                SCHOOL NAME GRADE  PROGRAM TYPE  \\\n",
      "0    1       M        M015  P.S. 015 Roberto Clemente     0K       GEN ED   \n",
      "1    1       M        M015  P.S. 015 Roberto Clemente     0K          CTT   \n",
      "2    1       M        M015  P.S. 015 Roberto Clemente     01       GEN ED   \n",
      "3    1       M        M015  P.S. 015 Roberto Clemente     01          CTT   \n",
      "4    1       M        M015  P.S. 015 Roberto Clemente     02       GEN ED   \n",
      "\n",
      "  CORE SUBJECT (MS CORE and 9-12 ONLY) CORE COURSE (MS CORE and 9-12 ONLY)  \\\n",
      "0                                    -                                   -   \n",
      "1                                    -                                   -   \n",
      "2                                    -                                   -   \n",
      "3                                    -                                   -   \n",
      "4                                    -                                   -   \n",
      "\n",
      "  SERVICE CATEGORY(K-9* ONLY)  NUMBER OF STUDENTS / SEATS FILLED  \\\n",
      "0                           -                               19.0   \n",
      "1                           -                               21.0   \n",
      "2                           -                               17.0   \n",
      "3                           -                               17.0   \n",
      "4                           -                               15.0   \n",
      "\n",
      "   NUMBER OF SECTIONS  AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  \\\n",
      "0                 1.0                19.0                    19.0   \n",
      "1                 1.0                21.0                    21.0   \n",
      "2                 1.0                17.0                    17.0   \n",
      "3                 1.0                17.0                    17.0   \n",
      "4                 1.0                15.0                    15.0   \n",
      "\n",
      "   SIZE OF LARGEST CLASS DATA SOURCE  SCHOOLWIDE PUPIL-TEACHER RATIO  \\\n",
      "0                   19.0         ATS                             NaN   \n",
      "1                   21.0         ATS                             NaN   \n",
      "2                   17.0         ATS                             NaN   \n",
      "3                   17.0         ATS                             NaN   \n",
      "4                   15.0         ATS                             NaN   \n",
      "\n",
      "  padded_csd     DBN  \n",
      "0         01  01M015  \n",
      "1         01  01M015  \n",
      "2         01  01M015  \n",
      "3         01  01M015  \n",
      "4         01  01M015  \n"
     ]
    }
   ],
   "source": [
    "data[\"hs_directory\"][\"DBN\"] = data[\"hs_directory\"][\"dbn\"]\n",
    "\n",
    "def pad_csd(num):\n",
    "    string_representation = str(num)\n",
    "    if len(string_representation) > 1:\n",
    "        return string_representation\n",
    "    else:\n",
    "        return string_representation.zfill(2)\n",
    "    \n",
    "data[\"class_size\"][\"padded_csd\"] = data[\"class_size\"][\"CSD\"].apply(pad_csd)\n",
    "data[\"class_size\"][\"DBN\"] = data[\"class_size\"][\"padded_csd\"] + data[\"class_size\"][\"SCHOOL CODE\"]\n",
    "print(data[\"class_size\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1122.0\n",
       "1    1172.0\n",
       "2    1149.0\n",
       "3    1174.0\n",
       "4    1207.0\n",
       "Name: sat_score, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conversion individual score from string to numeric and adding up\n",
    "data[\"sat_results\"][\"SAT Math Avg. Score\"]=pd.to_numeric(data[\"sat_results\"][\"SAT Math Avg. Score\"],errors=\"coerce\")\n",
    "data[\"sat_results\"][\"SAT Critical Reading Avg. Score\"]=pd.to_numeric(data[\"sat_results\"][\"SAT Critical Reading Avg. Score\"],errors=\"coerce\")\n",
    "data[\"sat_results\"][\"SAT Writing Avg. Score\"]=pd.to_numeric(data[\"sat_results\"][\"SAT Writing Avg. Score\"],errors=\"coerce\")\n",
    "#new colummn sat_score , addition of above 3 scores\n",
    "data[\"sat_results\"][\"sat_score\"]=data[\"sat_results\"][\"SAT Math Avg. Score\"] + data[\"sat_results\"][\"SAT Critical Reading Avg. Score\"] + data[\"sat_results\"][\"SAT Writing Avg. Score\"]\n",
    "\n",
    "data[\"sat_results\"][\"sat_score\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing Geographic Coordinates for Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dbn                                        school_name       boro  \\\n",
      "0  17K548                Brooklyn School for Music & Theatre   Brooklyn   \n",
      "1  09X543                   High School for Violin and Dance      Bronx   \n",
      "2  09X327        Comprehensive Model School Project M.S. 327      Bronx   \n",
      "3  02M280     Manhattan Early College School for Advertising  Manhattan   \n",
      "4  28Q680  Queens Gateway to Health Sciences Secondary Sc...     Queens   \n",
      "\n",
      "  building_code    phone_number    fax_number grade_span_min  grade_span_max  \\\n",
      "0          K440    718-230-6250  718-230-6262              9              12   \n",
      "1          X400    718-842-0687  718-589-9849              9              12   \n",
      "2          X240    718-294-8111  718-294-8109              6              12   \n",
      "3          M520  718-935-3477             NaN              9              10   \n",
      "4          Q695    718-969-3155  718-969-3552              6              12   \n",
      "\n",
      "  expgrade_span_min  expgrade_span_max         ...          \\\n",
      "0               NaN                NaN         ...           \n",
      "1               NaN                NaN         ...           \n",
      "2               NaN                NaN         ...           \n",
      "3                 9               14.0         ...           \n",
      "4               NaN                NaN         ...           \n",
      "\n",
      "                            priority04                       priority05  \\\n",
      "0                                  NaN                              NaN   \n",
      "1      Then to New York City residents                              NaN   \n",
      "2  Then to Bronx students or residents  Then to New York City residents   \n",
      "3      Then to New York City residents                              NaN   \n",
      "4      Then to New York City residents                              NaN   \n",
      "\n",
      "  priority06 priority07 priority08  priority09 priority10  \\\n",
      "0        NaN        NaN        NaN         NaN        NaN   \n",
      "1        NaN        NaN        NaN         NaN        NaN   \n",
      "2        NaN        NaN        NaN         NaN        NaN   \n",
      "3        NaN        NaN        NaN         NaN        NaN   \n",
      "4        NaN        NaN        NaN         NaN        NaN   \n",
      "\n",
      "                                          Location 1     DBN  \\\n",
      "0  883 Classon Avenue\\nBrooklyn, NY 11225\\n(40.67...  17K548   \n",
      "1  1110 Boston Road\\nBronx, NY 10456\\n(40.8276026...  09X543   \n",
      "2  1501 Jerome Avenue\\nBronx, NY 10452\\n(40.84241...  09X327   \n",
      "3  411 Pearl Street\\nNew York, NY 10038\\n(40.7106...  02M280   \n",
      "4  160-20 Goethals Avenue\\nJamaica, NY 11432\\n(40...  28Q680   \n",
      "\n",
      "                  lat  \n",
      "0   40.67029890700047  \n",
      "1    40.8276026690005  \n",
      "2  40.842414068000494  \n",
      "3   40.71067947100045  \n",
      "4  40.718810094000446  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def find_lat(loc):\n",
    "    coords = re.findall(\"\\(.+, .+\\)\", loc)\n",
    "    lat = coords[0].split(\",\")[0].replace(\"(\", \"\")\n",
    "    return lat\n",
    "\n",
    "data[\"hs_directory\"][\"lat\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_lat)\n",
    "\n",
    "print(data[\"hs_directory\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def find_lon(loc):\n",
    "    coords = re.findall(\"\\(.+, .+\\)\", loc)\n",
    "    lon = coords[0].split(\",\")[1].replace(\")\", \"\")\n",
    "    return lon\n",
    "\n",
    "data[\"hs_directory\"][\"lon\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_lon)\n",
    "data[\"hs_directory\"][\"lon\"] =pd.to_numeric(data[\"hs_directory\"][\"lon\"] ,errors=\"coerce\")\n",
    "data[\"hs_directory\"][\"lat\"]=pd.to_numeric(data[\"hs_directory\"][\"lat\"],errors=\"coerce\")\n",
    "\n",
    "#print(data[\"hs_directory\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condensing the Class Size Data Set-- coz we need only high school students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_size=data[\"class_size\"] \n",
    "class_size=class_size[class_size[\"GRADE \"]==\"09-12\"]\n",
    "class_size=class_size[class_size[\"PROGRAM TYPE\"]==\"GEN ED\"]\n",
    "#print(class_size.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Average Class Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CSD  NUMBER OF STUDENTS / SEATS FILLED  NUMBER OF SECTIONS  \\\n",
      "DBN                                                                  \n",
      "01M292    1                            88.0000            4.000000   \n",
      "01M332    1                            46.0000            2.000000   \n",
      "01M378    1                            33.0000            1.000000   \n",
      "01M448    1                           105.6875            4.750000   \n",
      "01M450    1                            57.6000            2.733333   \n",
      "\n",
      "        AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  SIZE OF LARGEST CLASS  \\\n",
      "DBN                                                                         \n",
      "01M292           22.564286                   18.50              26.571429   \n",
      "01M332           22.000000                   21.00              23.500000   \n",
      "01M378           33.000000                   33.00              33.000000   \n",
      "01M448           22.231250                   18.25              27.062500   \n",
      "01M450           21.200000                   19.40              22.866667   \n",
      "\n",
      "        SCHOOLWIDE PUPIL-TEACHER RATIO  \n",
      "DBN                                     \n",
      "01M292                             NaN  \n",
      "01M332                             NaN  \n",
      "01M378                             NaN  \n",
      "01M448                             NaN  \n",
      "01M450                             NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "class_size=class_size.groupby(\"DBN\").agg(numpy.mean)\n",
    "print(class_size.head())\n",
    "class_size.reset_index(inplace=True)\n",
    "data[\"class_size\"]=class_size\n",
    "#print(data[\"class_size\"].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condensing the Demographics Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>Name</th>\n",
       "      <th>schoolyear</th>\n",
       "      <th>fl_percent</th>\n",
       "      <th>frl_percent</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>prek</th>\n",
       "      <th>k</th>\n",
       "      <th>grade1</th>\n",
       "      <th>grade2</th>\n",
       "      <th>...</th>\n",
       "      <th>black_num</th>\n",
       "      <th>black_per</th>\n",
       "      <th>hispanic_num</th>\n",
       "      <th>hispanic_per</th>\n",
       "      <th>white_num</th>\n",
       "      <th>white_per</th>\n",
       "      <th>male_num</th>\n",
       "      <th>male_per</th>\n",
       "      <th>female_num</th>\n",
       "      <th>female_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01M015</td>\n",
       "      <td>P.S. 015 ROBERTO CLEMENTE</td>\n",
       "      <td>20112012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.4</td>\n",
       "      <td>189</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>33.3</td>\n",
       "      <td>109</td>\n",
       "      <td>57.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>51.3</td>\n",
       "      <td>92.0</td>\n",
       "      <td>48.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01M019</td>\n",
       "      <td>P.S. 019 ASHER LEVY</td>\n",
       "      <td>20112012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.5</td>\n",
       "      <td>328</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>24.7</td>\n",
       "      <td>158</td>\n",
       "      <td>48.2</td>\n",
       "      <td>28</td>\n",
       "      <td>8.5</td>\n",
       "      <td>147.0</td>\n",
       "      <td>44.8</td>\n",
       "      <td>181.0</td>\n",
       "      <td>55.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>01M020</td>\n",
       "      <td>PS 020 ANNA SILVER</td>\n",
       "      <td>20112012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.5</td>\n",
       "      <td>626</td>\n",
       "      <td>52</td>\n",
       "      <td>102</td>\n",
       "      <td>121</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>8.8</td>\n",
       "      <td>357</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.6</td>\n",
       "      <td>330.0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>296.0</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>01M034</td>\n",
       "      <td>PS 034 FRANKLIN D ROOSEVELT</td>\n",
       "      <td>20112012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.7</td>\n",
       "      <td>401</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>22.4</td>\n",
       "      <td>275</td>\n",
       "      <td>68.6</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>50.9</td>\n",
       "      <td>197.0</td>\n",
       "      <td>49.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>01M063</td>\n",
       "      <td>PS 063 WILLIAM MCKINLEY</td>\n",
       "      <td>20112012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.9</td>\n",
       "      <td>176</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>23.3</td>\n",
       "      <td>110</td>\n",
       "      <td>62.5</td>\n",
       "      <td>15</td>\n",
       "      <td>8.5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>55.1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DBN                                              Name  schoolyear  \\\n",
       "6   01M015  P.S. 015 ROBERTO CLEMENTE                           20112012   \n",
       "13  01M019  P.S. 019 ASHER LEVY                                 20112012   \n",
       "20  01M020  PS 020 ANNA SILVER                                  20112012   \n",
       "27  01M034  PS 034 FRANKLIN D ROOSEVELT                         20112012   \n",
       "35  01M063  PS 063 WILLIAM MCKINLEY                             20112012   \n",
       "\n",
       "   fl_percent  frl_percent  total_enrollment prek    k grade1 grade2  \\\n",
       "6         NaN         89.4               189   13   31     35     28   \n",
       "13        NaN         61.5               328   32   46     52     54   \n",
       "20        NaN         92.5               626   52  102    121     87   \n",
       "27        NaN         99.7               401   14   34     38     36   \n",
       "35        NaN         78.9               176   18   20     30     21   \n",
       "\n",
       "      ...     black_num black_per hispanic_num hispanic_per white_num  \\\n",
       "6     ...            63      33.3          109         57.7         4   \n",
       "13    ...            81      24.7          158         48.2        28   \n",
       "20    ...            55       8.8          357         57.0        16   \n",
       "27    ...            90      22.4          275         68.6         8   \n",
       "35    ...            41      23.3          110         62.5        15   \n",
       "\n",
       "   white_per male_num male_per female_num female_per  \n",
       "6        2.1     97.0     51.3       92.0       48.7  \n",
       "13       8.5    147.0     44.8      181.0       55.2  \n",
       "20       2.6    330.0     52.7      296.0       47.3  \n",
       "27       2.0    204.0     50.9      197.0       49.1  \n",
       "35       8.5     97.0     55.1       79.0       44.9  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics=data[\"demographics\"] \n",
    "\n",
    "demographics=demographics[demographics[\"schoolyear\"]==20112012]\n",
    "data[\"demographics\"] =demographics\n",
    "data[\"demographics\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condensing the Graduation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graduation=data[\"graduation\"]\n",
    "graduation=graduation[graduation[\"Cohort\"]==\"2006\"]\n",
    "graduation=graduation[graduation[\"Demographic\"]==\"Total Cohort\"]\n",
    "data[\"graduation\"]=graduation\n",
    "#print(data[\"graduation\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting AP Test Scores-from string to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['AP Test Takers ', 'Total Exams Taken', 'Number of Exams with scores 3 4 or 5']\n",
    "ap_2010=data['ap_2010']\n",
    "for cols in cols:\n",
    "    ap_2010[cols]=pd.to_numeric(ap_2010[cols],errors=\"coerce\")\n",
    "data[\"ap_2010\"]=ap_2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the dataset using left outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479, 33)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = data[\"sat_results\"]\n",
    "combined=combined.merge(data[\"ap_2010\"],how=\"left\")\n",
    "combined=combined.merge(data[\"graduation\"],how=\"left\")\n",
    "combined.shape\n",
    "#print(combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "For remaining datasets --using inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363, 285)\n"
     ]
    }
   ],
   "source": [
    "combined=combined.merge(data[\"class_size\"],how=\"inner\",on=\"DBN\")\n",
    "combined=combined.merge(data[\"demographics\"],how=\"inner\",on=\"DBN\")\n",
    "combined=combined.merge(data[\"survey\"],how=\"inner\",on=\"DBN\")\n",
    "combined=combined.merge(data[\"hs_directory\"],how=\"inner\",on=\"DBN\")\n",
    "print(combined.shape)\n",
    "#print(combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(combined.mean())\n",
    "combined=combined.fillna(combined.mean())\n",
    "combined=combined.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    01\n",
       "1    01\n",
       "2    01\n",
       "3    01\n",
       "4    01\n",
       "Name: school_dist, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def schooldist(col):\n",
    "    dist=col[0:2]\n",
    "    return dist\n",
    "combined[\"school_dist\"]=combined[\"DBN\"].apply(schooldist)\n",
    "combined[\"school_dist\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
